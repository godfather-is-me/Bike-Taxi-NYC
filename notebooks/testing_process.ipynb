{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_timestamp, date_format, year, month, hour, dayofyear, dayofweek, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/18 21:16:35 WARN Utils: Your hostname, J-L resolves to a loopback address: 127.0.1.1; using 172.18.124.253 instead (on interface eth0)\n",
      "22/08/18 21:16:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/18 21:16:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.18.124.253:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Testing process</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3978371670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SparkSession.builder.appName(\"Testing process\").getOrCreate()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-01 11:30:10|2021-01-01 11:36:12|         142|          43|\n",
      "|2021-01-01 11:51:20|2021-01-01 11:52:19|         238|         151|\n",
      "|2021-01-01 11:31:49|2021-01-01 11:48:21|          68|          33|\n",
      "|2021-01-01 11:16:29|2021-01-01 11:24:30|         224|          68|\n",
      "|2021-01-01 11:12:29|2021-01-01 11:30:34|          90|          40|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "dir = \"../data/curated/yellow/\"\n",
    "folder_locs = os.listdir(dir)\n",
    "\n",
    "yellow_list = []\n",
    "for folder in folder_locs:\n",
    "    path = dir + \"/\" + folder\n",
    "    yellow_list.append(sp.read.parquet(path))\n",
    "\n",
    "yellow = reduce(DataFrame.unionAll, yellow_list)\n",
    "yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38822801"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-01 11:15:56|2021-01-01 11:19:52|          43|         151|\n",
      "|2021-01-01 11:25:59|2021-01-01 11:34:44|         166|         239|\n",
      "|2021-01-01 11:45:57|2021-01-01 11:51:55|          41|          42|\n",
      "|2021-01-01 10:57:51|2021-01-01 11:04:56|         168|          75|\n",
      "|2021-01-01 11:35:13|2021-01-01 11:44:44|          74|         238|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir = \"../data/curated/green/\"\n",
    "folder_locs = os.listdir(dir)\n",
    "\n",
    "green_list = []\n",
    "for folder in folder_locs:\n",
    "    path = dir + \"/\" + folder\n",
    "    green_list.append(sp.read.parquet(path))\n",
    "\n",
    "green = reduce(DataFrame.unionAll, green_list)\n",
    "green.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672658"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-01 11:33:44|2021-01-01 11:49:07|         230|         166|\n",
      "|2021-01-01 11:23:56|2021-01-01 11:38:05|         233|         142|\n",
      "|2021-01-01 11:42:51|2021-01-01 11:45:50|         142|         143|\n",
      "|2021-01-01 11:06:59|2021-01-01 11:43:01|          88|          42|\n",
      "|2021-01-01 11:50:00|2021-01-01 12:04:57|          42|         151|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir = \"../data/curated/fhvhv/\"\n",
    "folder_locs = os.listdir(dir)\n",
    "\n",
    "uber_list = []\n",
    "for folder in folder_locs:\n",
    "    path = dir + \"/\" + folder\n",
    "    uber_list.append(sp.read.parquet(path))\n",
    "\n",
    "uber = reduce(DataFrame.unionAll, uber_list)\n",
    "uber.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128168181"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+\n",
      "|          started_at|            ended_at|PULocationID|DOLocationID|\n",
      "+--------------------+--------------------+------------+------------+\n",
      "|2021-01-09 14:13:...|2021-01-09 14:24:...|         164|         211|\n",
      "|2021-01-09 14:17:...|2021-01-09 14:24:...|         164|         100|\n",
      "|2021-01-09 14:19:...|2021-01-09 14:30:...|         164|          68|\n",
      "|2021-01-09 14:23:...|2021-01-09 14:32:...|         164|         107|\n",
      "|2021-01-09 14:27:...|2021-01-09 14:38:...|         164|         107|\n",
      "+--------------------+--------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir = \"../data/curated/citi/\"\n",
    "folder_locs = os.listdir(dir)\n",
    "\n",
    "citi_list = []\n",
    "for folder in folder_locs:\n",
    "    path = dir + \"/\" + folder\n",
    "    citi_list.append(sp.read.parquet(path))\n",
    "\n",
    "citi = reduce(DataFrame.unionAll, citi_list)\n",
    "citi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33561277"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/19 01:26:58 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 12645962 ms exceeds timeout 120000 ms\n",
      "22/08/19 01:26:58 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "citi.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-01 11:30:10|2021-01-01 11:36:12|         142|          43|\n",
      "|2021-01-01 11:51:20|2021-01-01 11:52:19|         238|         151|\n",
      "|2021-01-01 11:31:49|2021-01-01 11:48:21|          68|          33|\n",
      "|2021-01-01 11:16:29|2021-01-01 11:24:30|         224|          68|\n",
      "|2021-01-01 11:12:29|2021-01-01 11:30:34|          90|          40|\n",
      "|2021-01-01 11:26:12|2021-01-01 11:39:46|         263|         142|\n",
      "|2021-01-01 11:15:52|2021-01-01 11:38:07|         164|         255|\n",
      "|2021-01-01 11:46:36|2021-01-01 11:53:45|         255|          80|\n",
      "|2021-01-01 11:17:48|2021-01-01 11:21:55|         236|         237|\n",
      "|2021-01-01 11:33:38|2021-01-01 11:38:37|         142|         239|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167663640"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis = reduce(DataFrame.unionAll, [yellow, green, uber])\n",
    "taxis.show(10)\n",
    "taxis.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp.read.parquet(\"../data/processed/merged/\")\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data count before dropping null values\")\n",
    "print(data.count())\n",
    "print(\"Data count after dropping null values\")\n",
    "data.dropna().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are no null values and the data has been merged successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process time difference and extract date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+----+-----+---+--------+-------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|year|month|day|time_bin|trip_duration|\n",
      "+-------------------+-------------------+------------+------------+----+-----+---+--------+-------------+\n",
      "|2021-01-01 11:23:24|2021-01-01 11:34:29|         140|         142|2021|    1|  1|      11|          665|\n",
      "|2021-01-01 11:11:28|2021-01-01 11:38:24|         113|         228|2021|    1|  1|      11|         1616|\n",
      "|2021-01-01 11:38:04|2021-01-01 11:47:02|         107|         262|2021|    1|  1|      11|          538|\n",
      "|2021-01-01 11:07:52|2021-01-01 11:10:42|          43|         237|2021|    1|  1|      11|          170|\n",
      "|2021-01-01 11:25:04|2021-01-01 11:30:16|         230|         142|2021|    1|  1|      11|          312|\n",
      "+-------------------+-------------------+------------+------------+----+-----+---+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform feature engineering\n",
    "time_diff = col(\"dropoff_datetime\").cast(\"long\") - col(\"pickup_datetime\").cast(\"long\")\n",
    "sample = taxis.sample(0.01, 123)\n",
    "taxi_process = (\n",
    "    sample\n",
    "    .withColumn(\"year\", year(sample.pickup_datetime))\n",
    "    .withColumn(\"month\", month(sample.pickup_datetime))\n",
    "    .withColumn(\"day\", dayofweek(sample.pickup_datetime))\n",
    "    .withColumn(\"time_bin\", hour(taxis.pickup_datetime))\n",
    "    .withColumn(\"trip_duration\", time_diff)\n",
    ")\n",
    "\n",
    "taxi_process.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge on group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:====================================================>(344 + 2) / 346]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+-----+\n",
      "|year|month|day|time_bin|count|\n",
      "+----+-----+---+--------+-----+\n",
      "|2021|    1|  2|      11|   35|\n",
      "|2021|    1|  4|      10|   40|\n",
      "|2021|    1|  8|       4|  134|\n",
      "|2021|    1| 15|      12|   13|\n",
      "|2021|    1| 28|       4|  129|\n",
      "|2021|    1| 30|       1|  127|\n",
      "|2021|    1| 11|      23|   71|\n",
      "|2021|    1| 20|      16|   20|\n",
      "|2021|    1| 28|       8|   74|\n",
      "|2021|    1|  3|       9|   74|\n",
      "|2021|    1| 23|       3|  143|\n",
      "|2021|    1| 29|       6|  141|\n",
      "|2021|    1| 29|      22|  125|\n",
      "|2021|    1| 15|       5|  128|\n",
      "|2021|    1|  8|      21|   85|\n",
      "|2021|    1|  5|       8|   41|\n",
      "|2021|    1| 12|       6|   79|\n",
      "|2021|    1| 29|      17|   48|\n",
      "|2021|    1|  4|      20|   85|\n",
      "|2021|    1| 21|       5|  146|\n",
      "|2021|    1| 23|      18|   32|\n",
      "|2021|    1|  6|      16|   19|\n",
      "|2021|    1| 11|      16|   13|\n",
      "|2021|    1| 26|       7|   68|\n",
      "|2021|    1| 29|      12|   27|\n",
      "|2021|    1|  8|      19|   82|\n",
      "|2021|    1|  3|      13|   25|\n",
      "|2021|    1|  5|       7|   45|\n",
      "|2021|    1|  7|       1|  102|\n",
      "|2021|    1| 26|      12|    8|\n",
      "|2021|    1| 14|       4|  121|\n",
      "|2021|    1| 24|      16|   12|\n",
      "|2021|    1|  7|      11|   24|\n",
      "|2021|    1| 13|      23|   82|\n",
      "|2021|    1| 18|       4|  109|\n",
      "|2021|    1| 21|      11|   29|\n",
      "|2021|    2| 32|       2|  132|\n",
      "|2021|    1| 15|       0|   89|\n",
      "|2021|    1| 20|       5|  126|\n",
      "|2021|    1| 23|       4|  164|\n",
      "|2021|    1| 26|      19|  149|\n",
      "|2021|    1| 28|      22|  109|\n",
      "|2021|    1| 16|       8|  122|\n",
      "|2021|    1| 16|      18|   40|\n",
      "|2021|    2| 32|       3|  140|\n",
      "|2021|    1|  3|       1|   96|\n",
      "|2021|    1| 24|      11|   66|\n",
      "|2021|    1| 30|      22|  128|\n",
      "|2021|    1| 16|      12|   52|\n",
      "|2021|    1| 29|      14|    9|\n",
      "+----+-----+---+--------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "taxi_process.groupBy([\"year\", \"month\", \"day\", \"time_bin\"]).count().show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the sample dataframe to merge weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+\n",
      "|               Date|Time bin|Temperature|Dew Point|Humidity|Wind Speed|Wind Gust|Pressure|Precipitation|    Condition|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+\n",
      "|2020-07-01 00:00:00|       0|       70.0|     65.0|    84.0|       6.0|      0.0|    29.9|          0.0|Partly Cloudy|\n",
      "|2020-07-01 00:00:00|       1|       70.0|     65.0|    84.0|       5.0|      0.0|    29.9|          0.0|Mostly Cloudy|\n",
      "|2020-07-01 00:00:00|       2|       70.0|     65.0|    84.0|       7.0|      0.0|    29.8|          0.0|Mostly Cloudy|\n",
      "|2020-07-01 00:00:00|       3|       69.0|     65.0|    87.0|       3.0|      0.0|    29.8|          0.0|Mostly Cloudy|\n",
      "|2020-07-01 00:00:00|       4|       69.0|     65.0|    87.0|       3.0|      0.0|    29.9|          0.0|Mostly Cloudy|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather2 = sp.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"../data/raw/weather/weather.csv\")\n",
    "weather2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|               Date|time_bin|Temperature|Dew Point|Humidity|Wind Speed|Wind Gust|Pressure|Precipitation|    Condition|year|month|day|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|2020-07-01 00:00:00|       0|       70.0|     65.0|    84.0|       6.0|      0.0|    29.9|          0.0|Partly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       1|       70.0|     65.0|    84.0|       5.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       2|       70.0|     65.0|    84.0|       7.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       3|       69.0|     65.0|    87.0|       3.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       4|       69.0|     65.0|    87.0|       3.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = sp.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"../data/raw/weather/weather.csv\")\n",
    "weather = weather.withColumnRenamed(\"Time bin\", \"time_bin\")\n",
    "weather = (weather\n",
    "    .withColumn(\"year\", year(weather.Date))\n",
    "    .withColumn(\"month\", month(weather.Date))\n",
    "    .withColumn(\"day\", dayofyear(weather.Date))\n",
    ")\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'timestamp'),\n",
       " ('time_bin', 'int'),\n",
       " ('Temperature', 'double'),\n",
       " ('Dew Point', 'double'),\n",
       " ('Humidity', 'double'),\n",
       " ('Wind Speed', 'double'),\n",
       " ('Wind Gust', 'double'),\n",
       " ('Pressure', 'double'),\n",
       " ('Precipitation', 'double'),\n",
       " ('Condition', 'string'),\n",
       " ('year', 'int'),\n",
       " ('month', 'int'),\n",
       " ('day', 'int')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check why bikes is not able to provide trip duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+\n",
      "|          started_at|            ended_at|PULocationID|DOLocationID|\n",
      "+--------------------+--------------------+------------+------------+\n",
      "|2021-01-05 17:35:...|2021-01-05 18:01:...|         164|           7|\n",
      "|2021-01-05 17:38:...|2021-01-05 17:43:...|         164|         107|\n",
      "|2021-01-05 17:51:...|2021-01-05 18:01:...|          37|         225|\n",
      "|2021-01-05 17:52:...|2021-01-05 17:59:...|         164|          68|\n",
      "|2021-01-05 17:54:...|2021-01-05 18:10:...|          37|         256|\n",
      "+--------------------+--------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir = \"../data/curated/citi/\"\n",
    "folder_locs = os.listdir(dir)\n",
    "\n",
    "citi_list = []\n",
    "for folder in folder_locs:\n",
    "    path = dir + \"/\" + folder\n",
    "    citi_list.append(sp.read.option(\"inferSchema\", True).parquet(path))\n",
    "\n",
    "citi = reduce(DataFrame.unionAll, citi_list)\n",
    "citi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('started_at', 'timestamp'),\n",
       " ('ended_at', 'timestamp'),\n",
       " ('PULocationID', 'bigint'),\n",
       " ('DOLocationID', 'bigint')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_columns(citi):\n",
    "    \"\"\"\n",
    "    Function for citibike data to match the same columns names so \n",
    "    it can go through the same feature processing\n",
    "    \"\"\"\n",
    "    citi = citi.withColumnRenamed(\"started_at\", \"pickup_datetime\")\n",
    "    return citi.withColumnRenamed(\"ended_at\", \"dropoff_datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+\n",
      "|     pickup_datetime|    dropoff_datetime|PULocationID|DOLocationID|\n",
      "+--------------------+--------------------+------------+------------+\n",
      "|2021-01-05 17:35:...|2021-01-05 18:01:...|         164|           7|\n",
      "|2021-01-05 17:38:...|2021-01-05 17:43:...|         164|         107|\n",
      "|2021-01-05 17:51:...|2021-01-05 18:01:...|          37|         225|\n",
      "|2021-01-05 17:52:...|2021-01-05 17:59:...|         164|          68|\n",
      "|2021-01-05 17:54:...|2021-01-05 18:10:...|          37|         256|\n",
      "+--------------------+--------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citi = match_columns(citi)\n",
    "citi.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge citi and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_features(data):\n",
    "    \"\"\"\n",
    "    Function to extract features directly from the datetime object\n",
    "    \"\"\"\n",
    "    processed = (\n",
    "        data\n",
    "        .withColumn(\"year\", year(data.pickup_datetime))\n",
    "        .withColumn(\"month\", month(data.pickup_datetime))\n",
    "        .withColumn(\"day\", dayofyear(data.pickup_datetime))\n",
    "        .withColumn(\"time_bin\", hour(data.pickup_datetime))\n",
    "    )\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+----+-----+---+--------+\n",
      "|     pickup_datetime|    dropoff_datetime|PULocationID|DOLocationID|year|month|day|time_bin|\n",
      "+--------------------+--------------------+------------+------------+----+-----+---+--------+\n",
      "|2021-01-07 15:26:...|2021-01-07 15:44:...|         142|          74|2021|    1|  7|      15|\n",
      "|2021-01-08 18:20:...|2021-01-08 18:29:...|         256|          80|2021|    1|  8|      18|\n",
      "|2021-01-09 01:19:...|2021-01-09 01:24:...|         256|         255|2021|    1|  9|       1|\n",
      "|2021-01-07 08:10:...|2021-01-07 08:13:...|         236|         237|2021|    1|  7|       8|\n",
      "|2021-01-07 19:03:...|2021-01-07 19:20:...|          33|         195|2021|    1|  7|      19|\n",
      "+--------------------+--------------------+------------+------------+----+-----+---+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|               Date|time_bin|Temperature|Dew Point|Humidity|Wind Speed|Wind Gust|Pressure|Precipitation|    Condition|year|month|day|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|2020-07-01 00:00:00|       0|       70.0|     65.0|    84.0|       6.0|      0.0|    29.9|          0.0|Partly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       0|       70.0|     65.0|    84.0|       5.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       0|       70.0|     65.0|    84.0|       7.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       0|       69.0|     65.0|    87.0|       3.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       0|       69.0|     65.0|    87.0|       3.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citi_sample = citi.sample(0.001)\n",
    "\n",
    "# Process datetime columns\n",
    "citi_sample = datetime_features(citi_sample)\n",
    "\n",
    "citi_sample.show(5)\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+--------------------+--------------------+------------+------------+----+-----------+---------+--------+----------+---------+--------+-------------+---------+\n",
      "|year|month|day|time_bin|     pickup_datetime|    dropoff_datetime|PULocationID|DOLocationID|Date|Temperature|Dew Point|Humidity|Wind Speed|Wind Gust|Pressure|Precipitation|Condition|\n",
      "+----+-----+---+--------+--------------------+--------------------+------------+------------+----+-----------+---------+--------+----------+---------+--------+-------------+---------+\n",
      "|2021|    1|  7|      15|2021-01-07 15:26:...|2021-01-07 15:44:...|         142|          74|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  8|      18|2021-01-08 18:20:...|2021-01-08 18:29:...|         256|          80|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  9|       1|2021-01-09 01:19:...|2021-01-09 01:24:...|         256|         255|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  7|       8|2021-01-07 08:10:...|2021-01-07 08:13:...|         236|         237|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  7|      19|2021-01-07 19:03:...|2021-01-07 19:20:...|          33|         195|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  8|      10|2021-01-08 10:04:...|2021-01-08 10:19:...|         263|          48|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  8|      17|2021-01-08 17:20:...|2021-01-08 17:27:...|         148|          79|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  8|      19|2021-01-08 19:17:...|2021-01-08 19:41:...|          43|          75|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  9|      13|2021-01-09 13:43:...|2021-01-09 13:56:...|         148|         256|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "|2021|    1|  9|      14|2021-01-09 14:07:...|2021-01-09 14:27:...|          37|          34|null|       null|     null|    null|      null|     null|    null|         null|     null|\n",
      "+----+-----+---+--------+--------------------+--------------------+------------+------------+----+-----------+---------+--------+----------+---------+--------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged = citi_sample.join(weather, [\"year\", \"month\", \"day\", \"time_bin\"], how=\"left\")\n",
    "merged.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|      Date|Time_bin|Temperature|Dew Point|Humidity|Wind Speed|Wind Gust|Pressure|Precipitation|    Condition|Year|Month|Day|\n",
      "+----------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|2020-07-01|       0|       70.0|     65.0|    84.0|       6.0|      0.0|    29.9|          0.0|Partly Cloudy|2020|    7|183|\n",
      "|2020-07-01|       0|       70.0|     65.0|    84.0|       5.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01|       0|       70.0|     65.0|    84.0|       7.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01|       0|       69.0|     65.0|    87.0|       3.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01|       0|       69.0|     65.0|    87.0|       3.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "+----------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'string'),\n",
       " ('Time_bin', 'int'),\n",
       " ('Temperature', 'string'),\n",
       " ('Dew Point', 'string'),\n",
       " ('Humidity', 'string'),\n",
       " ('Wind Speed', 'string'),\n",
       " ('Wind Gust', 'string'),\n",
       " ('Pressure', 'string'),\n",
       " ('Precipitation', 'string'),\n",
       " ('Condition', 'string'),\n",
       " ('Year', 'int'),\n",
       " ('Month', 'int'),\n",
       " ('Day', 'int')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+-------------+\n",
      "| id|category|categoryIndex|  categoryVec|\n",
      "+---+--------+-------------+-------------+\n",
      "|  0|       a|          0.0|(2,[0],[1.0])|\n",
      "|  1|       b|          2.0|    (2,[],[])|\n",
      "|  2|       c|          1.0|(2,[1],[1.0])|\n",
      "|  3|       a|          0.0|(2,[0],[1.0])|\n",
      "|  4|       a|          0.0|(2,[0],[1.0])|\n",
      "|  5|       c|          1.0|(2,[1],[1.0])|\n",
      "+---+--------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "#from pyspark import SQLContext\n",
    "\n",
    "df = sp.createDataFrame([\n",
    "  (0, \"a\"),\n",
    "  (1, \"b\"),\n",
    "  (2, \"c\"),\n",
    "  (3, \"a\"),\n",
    "  (4, \"a\"),\n",
    "  (5, \"c\")\n",
    "], [\"id\", \"category\"])\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"categoryIndex\", outputCol=\"categoryVec\", dropLast=True)\n",
    "encoded = encoder.fit(indexed).transform(indexed)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  0|       a|\n",
      "|  1|       b|\n",
      "|  2|       c|\n",
      "|  3|       a|\n",
      "|  4|       a|\n",
      "|  5|       c|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|               Date|time_bin|Temperature|Dew Point|Humidity|Wind Speed|Wind Gust|Pressure|Precipitation|    Condition|year|month|day|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "|2020-07-01 00:00:00|       0|       70.0|     65.0|    84.0|       6.0|      0.0|    29.9|          0.0|Partly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       1|       70.0|     65.0|    84.0|       5.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       2|       70.0|     65.0|    84.0|       7.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       3|       69.0|     65.0|    87.0|       3.0|      0.0|    29.8|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "|2020-07-01 00:00:00|       4|       69.0|     65.0|    87.0|       3.0|      0.0|    29.9|          0.0|Mostly Cloudy|2020|    7|183|\n",
      "+-------------------+--------+-----------+---------+--------+----------+---------+--------+-------------+-------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = sp.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"../data/raw/weather/weather.csv\")\n",
    "weather = weather.withColumnRenamed(\"Time bin\", \"time_bin\")\n",
    "weather = (weather\n",
    "    .withColumn(\"year\", year(weather.Date))\n",
    "    .withColumn(\"month\", month(weather.Date))\n",
    "    .withColumn(\"day\", dayofyear(weather.Date))\n",
    ")\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('virtual')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "064aedc1eb8b7d9f9e1500e028db0dd8866d569cb38718b1182d0602d551f688"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
